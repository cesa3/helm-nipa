server:
  # Global settings are defined here to override chart defaults correctly.
  global:
    scrape_interval: 15s
    evaluation_interval: 15s
    scrape_timeout: 10s
    external_labels:
      cluster: 'ingress-performance-test'

  replicaCount: 1
  
  # Resource allocation
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 2000m
      memory: 4Gi

  # Persistence
  persistentVolume:
    enabled: true
    size: 5Gi
    storageClass: "local-path"

  # Service configuration
  service:
    type: NodePort
    nodePort: 30090
    servicePort: 80

  # Retention settings
  retention: 15d

# AlertManager (optional)
alertmanager:
  enabled: false

# Node Exporter (for system metrics)
nodeExporter:
  enabled: true
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 200m
      memory: 256Mi

# Kube State Metrics (for k8s metrics)
kubeStateMetrics:
  enabled: true
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 200m
      memory: 256Mi

# Push Gateway (optional)
pushgateway:
  enabled: false

# serverFiles contains the configuration files for Prometheus.
serverFiles:
  # prometheus.yml configuration is placed here.
  # The 'global' block is handled by 'server.global' above and will be added automatically by the chart.
  prometheus.yml:
    rule_files:
      - /etc/config/rules/*.yml # Correct path for rule files
    scrape_configs:
      # Prometheus itself
      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']

      # Kubernetes API server
      - job_name: 'kubernetes-apiservers'
        kubernetes_sd_configs:
          - role: endpoints
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
            action: keep
            regex: default;kubernetes;https

      # Kubernetes nodes (kubelet)
      - job_name: 'kubernetes-nodes'
        kubernetes_sd_configs:
          - role: node
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/${1}/proxy/metrics

      # Kubernetes nodes (cadvisor)
      - job_name: 'kubernetes-cadvisor'
        kubernetes_sd_configs:
          - role: node
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor

      # Kubernetes pods (for dynamic discovery of ingress controllers)
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: kubernetes_pod_name

      # Your application metrics (frontend)
      - job_name: 'nipa-frontend'
        kubernetes_sd_configs:
          - role: endpoints
        relabel_configs:
          - source_labels: [__meta_kubernetes_service_name]
            action: keep
            regex: frontend
          - source_labels: [__meta_kubernetes_endpoint_port_name]
            action: keep
            regex: http

      # Your application metrics (backend)
      - job_name: 'nipa-backend'
        kubernetes_sd_configs:
          - role: endpoints
        relabel_configs:
          - source_labels: [__meta_kubernetes_service_name]
            action: keep
            regex: backend
          - source_labels: [__meta_kubernetes_endpoint_port_name]
            action: keep
            regex: http

  # Rule files are defined under the 'rules' key inside 'serverFiles'
  rules:
    recording_rules.yml:
      groups:
        - name: ingress_performance
          interval: 30s
          rules:
            # Request rate
            - record: ingress:request_rate
              expr: rate(nginx_ingress_controller_requests[5m])
            
            # Request duration percentiles
            - record: ingress:request_duration_p50
              expr: histogram_quantile(0.50, rate(nginx_ingress_controller_request_duration_seconds_bucket[5m]))
            
            - record: ingress:request_duration_p95
              expr: histogram_quantile(0.95, rate(nginx_ingress_controller_request_duration_seconds_bucket[5m]))
            
            - record: ingress:request_duration_p99
              expr: histogram_quantile(0.99, rate(nginx_ingress_controller_request_duration_seconds_bucket[5m]))

            # Error rate
            - record: ingress:error_rate
              expr: rate(nginx_ingress_controller_requests{status=~"5.."}[5m]) / rate(nginx_ingress_controller_requests[5m])

            # CPU usage
            - record: ingress:cpu_usage
              expr: rate(container_cpu_usage_seconds_total{pod=~".*ingress.*"}[5m])

            # Memory usage
            - record: ingress:memory_usage
              expr: container_memory_working_set_bytes{pod=~".*ingress.*"}
